{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import copy\n",
    "import glob\n",
    "import pickle\n",
    "import datetime\n",
    "import argparse\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.merge import merge\n",
    "\n",
    "from src.data.load import clean_test_shapefiles, clean_random_shapefile\n",
    "from src.data.prepare import prepare_data, get_crop_type_x_y_pos, get_valid_cropland_x_y\n",
    "from src.utils.logger import get_log_dir, get_logger\n",
    "from src.model.crop_type import test, predict, sample_unlabeled_idx #, evaluate_by_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def croptype_predict(args):\n",
    "    # read configure file\n",
    "    with open(args.config_filename) as f:\n",
    "        config = yaml.load(f)\n",
    "    data_kwargs = config.get('data')\n",
    "    model_kwargs = config.get('model')\n",
    "    train_kwargs = config.get('train')\n",
    "    predict_kwargs = config.get('predict')\n",
    "    # data path kwargs\n",
    "    print(\"getting data kwargs\")\n",
    "    img_dir = data_kwargs.get('img_dir')\n",
    "    ancillary_dir = data_kwargs.get('ancillary_dir')\n",
    "    # train kwargs\n",
    "    print(\"getting train kwargs\")\n",
    "    cv_type = train_kwargs.get('cv_type')\n",
    "    tiles_x = train_kwargs.get('tiles_x')\n",
    "    tiles_y = train_kwargs.get('tiles_y')\n",
    "    shape = train_kwargs.get('shape')\n",
    "    buffer_radius = train_kwargs.get('buffer_radius')\n",
    "    n_fold = train_kwargs.get('n_fold')\n",
    "    random_state = train_kwargs.get('random_state')\n",
    "    hp_search_by = train_kwargs.get('hp_search_by')\n",
    "    train_from = train_kwargs.get('train_from')\n",
    "    # model kwargs\n",
    "    print(\"getting model kwargs\")\n",
    "    fill_missing = model_kwargs.get('fill_missing')\n",
    "    check_missing = model_kwargs.get('check_missing')\n",
    "    scaling = model_kwargs.get('scaling')\n",
    "    study_scaling = model_kwargs.get('study_scaling')\n",
    "    engineer_feature = model_kwargs.get('engineer_feature')\n",
    "    new_bands_name = model_kwargs.get('new_bands_name')\n",
    "    smooth = model_kwargs.get('smooth')\n",
    "    models_name = model_kwargs.get('models_name')\n",
    "    pretrained = model_kwargs.get('pretrained')\n",
    "    # predict kwargs\n",
    "    print(\"getting predict kwargs\")\n",
    "    predict_labels_only = predict_kwargs.get('predict_labels_only')\n",
    "    color_by_height = predict_kwargs.get('color_by_height')\n",
    "\n",
    "    testing = False\n",
    "    \n",
    "\n",
    "    # logger\n",
    "    log_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    log_filename = f'crop_type_{log_time}_on_{pretrained}.log' if not testing else f'crop_type_testing_{log_time}_on_{pretrained}.log'\n",
    "    logger = get_logger(get_log_dir('./logs/'), __name__, log_filename, level='INFO')\n",
    "    logger.info(config)\n",
    "\n",
    "\n",
    "    logger.info('#### Test Crop Type Model')\n",
    "    test_near_dir = img_dir + '43SFR/raster/' if not testing else img_dir + '43SFR/raster_sample/'\n",
    "    test_far_dir = img_dir + '43RGQ/raster/' if not testing else img_dir + '43RGQ/raster_sample/'\n",
    "    predict_dir = img_dir + args.tile_id + '/raster/' if not testing else img_dir + args.tile_id + '/raster_sample/'\n",
    "    \n",
    "    return pretrained, predict_dir, test_near_dir, test_far_dir, logger, smooth, engineer_feature, scaling, new_bands_name, fill_missing, check_missing, args.vis_stack, args.vis_profile, 'apple', args.vis_afterprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallizing to 1 processes...\n",
      "getting data kwargs\n",
      "getting train kwargs\n",
      "getting model kwargs\n",
      "getting predict kwargs\n",
      "2022-03-07 10:44:59,850 - INFO - Log directory: ./logs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leds\\AppData\\Local\\Temp\\ipykernel_17560\\1000727752.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(f)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-07 10:44:59,872 - INFO - {'data': {'img_dir': 'N:/dataorg-datasets/MLsatellite/sentinel2_images/images_danya/', 'ancillary_dir': 'K:/2021-data-org/4. RESEARCH_n/ML/MLsatellite/Data/layers_india/ancilliary_data/'}, 'train': {'cv_type': 'block', 'tiles_x': 4, 'tiles_y': 4, 'shape': 'square', 'buffer_radius': 0, 'n_fold': 3, 'random_state': 24, 'hp_search_by': 'grid', 'train_from': 'cropland'}, 'model': {'fill_missing': 'linear', 'check_missing': False, 'scaling': 'as_reflectance', 'study_scaling': False, 'engineer_feature': 'temporal+spatial', 'new_bands_name': ['ndvi'], 'smooth': False, 'check_SAC': False, 'models_name': ['ocsvm', 'pul', 'pul-w'], 'pretrained': '20220105-135132_rfc'}, 'predict': {'predict_labels_only': True, 'color_by_height': True}}\n",
      "2022-03-07 10:44:59,892 - INFO - #### Test Crop Type Model\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--config_filename', type=str,\n",
    "                    default='./data/config/crop_type.yaml')\n",
    "\n",
    "parser.add_argument('--tile_ids', nargs='+', default=['43SFR'])\n",
    "parser.add_argument('--action', type=str, default='test_from_scratch',\n",
    "                    choices=['test_from_cropland', 'test_from_scratch', 'predict_from_scratch', 'predict_from_cropland', 'test_together'])\n",
    "parser.add_argument('--vis_stack', type=bool, default=False)\n",
    "parser.add_argument('--vis_profile', type=bool, default=False)\n",
    "parser.add_argument('--vis_afterprocess', type=bool, default=False)\n",
    "\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "args_list, tile_ids = [], args.tile_ids\n",
    "print(f'Parallizing to {len(tile_ids)} processes...')\n",
    "for tile_id in tile_ids:\n",
    "    args.tile_id = tile_id\n",
    "    args_list.append(copy.deepcopy(args))  # deep copy \n",
    "process_pool = multiprocessing.Pool(processes=len(tile_ids))\n",
    "#process_pool.map(croptype_predict, args_list)\n",
    "\n",
    "pretrained, predict_dir, test_near_dir, test_far_dir, logger, smooth, engineer_feature, scaling, new_bands_name, fill_missing, check_missing, vis_stack, vis_profile, vis_profile,vis_afterprocess = croptype_predict(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 1 multi-polygons to polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leds\\Anaconda3\\envs\\sat\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "C:\\Users\\leds\\Anaconda3\\envs\\sat\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n",
      "C:\\Users\\leds\\Anaconda3\\envs\\sat\\lib\\site-packages\\geopandas\\io\\file.py:362: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-07 10:46:09,727 - INFO - ### Test on kullu\n",
      "2022-03-07 10:46:09,753 - INFO - ### Prepare data\n",
      "2022-03-07 10:46:09,801 - INFO - # Stack timestamps weekly\n",
      "2022-03-07 10:47:16,787 - INFO -   [1/53] 2019-12-30 (x2020-01-03, 2020-01-05, )\n",
      "2022-03-07 10:49:02,363 - INFO -   [2/53] 2020-01-06 (2020-01-10, x2020-01-08, )\n",
      "2022-03-07 10:52:15,608 - INFO -   [3/53] 2020-01-13 (x2020-01-13, 2020-01-15, x2020-01-18, )\n",
      "2022-03-07 10:56:25,154 - INFO -   [4/53] 2020-01-20 (2020-01-20, x2020-01-23, 2020-01-25, )\n",
      "2022-03-07 10:58:55,267 - INFO -   [5/53] 2020-01-27 (x2020-02-02, x2020-01-28, )\n",
      "2022-03-07 11:01:56,618 - INFO -   [6/53] 2020-02-03 (2020-02-09, 2020-02-04, x2020-02-07, )\n",
      "2022-03-07 11:04:15,471 - INFO -   [7/53] 2020-02-10 (x2020-02-12, 2020-02-14, )\n",
      "2022-03-07 11:06:46,189 - INFO -   [8/53] 2020-02-17 (2020-02-19, x2020-02-22, x2020-02-17, )\n",
      "2022-03-07 11:11:48,826 - INFO -   [9/53] 2020-02-24 (2020-02-24, 2020-02-24, x2020-02-27, )\n",
      "2022-03-07 11:16:24,056 - INFO -   [10/53] 2020-03-02 (x2020-03-03, 2020-03-05, )\n",
      "2022-03-07 11:22:23,875 - INFO -   [11/53] 2020-03-09 (2020-03-10, x2020-03-13, 2020-03-15, )\n",
      "2022-03-07 11:25:57,778 - INFO -   [12/53] 2020-03-16 (2020-03-20, x2020-03-18, )\n",
      "2022-03-07 11:32:17,526 - INFO -   [13/53] 2020-03-23 (x2020-03-23, 2020-03-25, x2020-03-28, )\n",
      "2022-03-07 11:37:35,666 - INFO -   [14/53] 2020-03-30 (2020-03-30, x2020-04-02, 2020-04-04, )\n",
      "2022-03-07 11:42:55,705 - INFO -   [15/53] 2020-04-06 (2020-04-09, x2020-04-12, x2020-04-07, )\n",
      "2022-03-07 11:47:56,784 - INFO -   [16/53] 2020-04-13 (2020-04-19, 2020-04-14, x2020-04-17, )\n",
      "2022-03-07 11:51:43,620 - INFO -   [17/53] 2020-04-20 (x2020-04-22, 2020-04-24, )\n",
      "2022-03-07 11:55:28,745 - INFO -   [18/53] 2020-04-27 (2020-04-29, x2020-05-02, )\n",
      "2022-03-07 12:01:28,977 - INFO -   [19/53] 2020-05-04 (2020-05-09, 2020-05-04, x2020-05-07, )\n",
      "2022-03-07 12:05:02,652 - INFO -   [20/53] 2020-05-11 (x2020-05-12, 2020-05-14, )\n",
      "2022-03-07 12:08:28,706 - INFO -   [21/53] 2020-05-18 (x2020-05-22, 2020-05-24, )\n",
      "2022-03-07 12:12:34,415 - INFO -   [22/53] 2020-05-25 (2020-05-29, x2020-05-27, )\n",
      "2022-03-07 12:18:55,075 - INFO -   [23/53] 2020-06-01 (x2020-06-01, 2020-06-03, x2020-06-06, )\n",
      "2022-03-07 12:23:56,011 - INFO -   [24/53] 2020-06-08 (x2020-06-11, 2020-06-13, )\n",
      "2022-03-07 12:27:56,138 - INFO -   [25/53] 2020-06-15 (2020-06-18, x2020-06-21, )\n",
      "2022-03-07 12:33:44,334 - INFO -   [26/53] 2020-06-22 (2020-06-28, 2020-06-23, x2020-06-26, )\n",
      "2022-03-07 12:37:21,555 - INFO -   [27/53] 2020-06-29 (x2020-07-01, 2020-07-03, )\n",
      "2022-03-07 12:40:58,033 - INFO -   [28/53] 2020-07-06 (2020-07-08, x2020-07-11, )\n",
      "2022-03-07 12:46:42,068 - INFO -   [29/53] 2020-07-13 (2020-07-18, 2020-07-13, x2020-07-16, )\n",
      "2022-03-07 12:52:08,720 - INFO -   [30/53] 2020-07-20 (x2020-07-21, 2020-07-23, x2020-07-26, )\n",
      "2022-03-07 12:55:11,303 - INFO -   [31/53] 2020-07-27 (2020-07-28, 2020-08-02, )\n",
      "2022-03-07 12:58:24,560 - INFO -   [32/53] 2020-08-03 (2020-08-07, x2020-08-05, )\n",
      "2022-03-07 13:03:21,602 - INFO -   [33/53] 2020-08-10 (x2020-08-10, 2020-08-12, x2020-08-15, )\n",
      "2022-03-07 13:08:20,108 - INFO -   [34/53] 2020-08-17 (2020-08-17, x2020-08-20, 2020-08-22, )\n",
      "2022-03-07 13:09:51,734 - INFO -   [35/53] 2020-08-24 (x2020-08-25, )\n",
      "2022-03-07 13:14:27,652 - INFO -   [36/53] 2020-08-31 (2020-09-06, 2020-09-01, x2020-09-04, )\n",
      "2022-03-07 13:17:40,332 - INFO -   [37/53] 2020-09-07 (x2020-09-09, 2020-09-11, )\n",
      "2022-03-07 13:22:11,679 - INFO -   [38/53] 2020-09-14 (2020-09-16, x2020-09-19, x2020-09-14, )\n",
      "2022-03-07 13:25:11,248 - INFO -   [39/53] 2020-09-21 (2020-09-21, x2020-09-24, )\n",
      "2022-03-07 13:29:42,992 - INFO -   [40/53] 2020-09-28 (x2020-09-29, 2020-10-01, x2020-10-04, )\n",
      "2022-03-07 13:34:28,744 - INFO -   [41/53] 2020-10-05 (2020-10-06, x2020-10-09, 2020-10-11, )\n",
      "2022-03-07 13:37:36,871 - INFO -   [42/53] 2020-10-12 (2020-10-16, x2020-10-14, )\n",
      "2022-03-07 13:41:13,409 - INFO -   [43/53] 2020-10-19 (x2020-10-19, x2020-10-24, )\n",
      "2022-03-07 13:44:37,053 - INFO -   [44/53] 2020-10-26 (2020-10-26, x2020-10-29, )\n",
      "2022-03-07 13:50:53,423 - INFO -   [45/53] 2020-11-02 (2020-11-05, x2020-11-08, x2020-11-08, x2020-11-03, )\n",
      "2022-03-07 13:55:44,302 - INFO -   [46/53] 2020-11-09 (2020-11-15, 2020-11-10, x2020-11-13, )\n",
      "2022-03-07 13:57:22,141 - INFO -   [47/53] 2020-11-16 (2020-11-20, )\n",
      "2022-03-07 14:02:00,383 - INFO -   [48/53] 2020-11-23 (2020-11-25, x2020-11-28, x2020-11-23, )\n",
      "2022-03-07 14:05:06,357 - INFO -   [49/53] 2020-11-30 (2020-12-05, x2020-12-03, )\n",
      "2022-03-07 14:09:42,387 - INFO -   [50/53] 2020-12-07 (x2020-12-08, 2020-12-10, x2020-12-13, )\n",
      "2022-03-07 14:14:13,733 - INFO -   [51/53] 2020-12-14 (2020-12-15, x2020-12-18, 2020-12-20, )\n",
      "2022-03-07 14:17:19,964 - INFO -   [52/53] 2020-12-21 (2020-12-25, x2020-12-23, )\n",
      "2022-03-07 14:20:21,488 - INFO -   [53/53] 2020-12-28 (x2020-12-28, 2020-12-30, )\n",
      "2022-03-07 14:20:21,508 - INFO -   avg. cloud coverage = 0.4964\n",
      "2022-03-07 14:20:21,516 - INFO -   avg. filling ratio = 0.4964\n",
      "2022-03-07 14:20:21,531 - INFO -   avg. zero ratio = 0.4662\n"
     ]
    }
   ],
   "source": [
    "if args.action == 'test_from_scratch':\n",
    "    \n",
    "    label_path = f'./data/ground_truth/test_labels_combined/polygons_surveys_20210716_20210825_20211213_20220103.shp'\n",
    "    mandi_path, shimla_path, kullu_path = clean_random_shapefile(label_path)\n",
    "    label_path_dict = {'kullu': kullu_path}#, 'mandi': mandi_path, 'shimla': shimla_path}\n",
    "\n",
    "    test_dir_dict = {'kullu': test_near_dir} #, 'mandi': test_far_dir, 'shimla': test_far_dir}\n",
    "\n",
    "    pretrained = [pretrained] if isinstance(pretrained, str) else pretrained\n",
    "    \n",
    "    for district in test_dir_dict.keys():\n",
    "        logger.info(f'### Test on {district}')\n",
    "        test_dir = test_dir_dict[district]\n",
    "        \n",
    "        # prepare data\n",
    "        df_te, meta, feature_names, polygons_list = \\\n",
    "            prepare_data(logger=logger, dataset=f'test_{district}', feature_dir=test_dir,\n",
    "                            label_path=label_path_dict[district], window=None, smooth=smooth,\n",
    "                            engineer_feature=engineer_feature, scaling=scaling, new_bands_name=new_bands_name,\n",
    "                            fill_missing=fill_missing, check_missing=check_missing,\n",
    "                            vis_stack=args.vis_stack, vis_profile=args.vis_profile, vis_profile_type='cropland',\n",
    "                            vis_afterprocess=args.vis_afterprocess)\n",
    "        n_feature = len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 14:46:57,624 - INFO -   label = 1, pixel number = 6743, percentage = 100.0%\n"
     ]
    }
   ],
   "source": [
    "def get_crop_type_x_y_pos_test(logger, df, n_feature, dataset):\n",
    "    # was in prepare.py\n",
    "    \n",
    "    mask_valid = (df.label.values != 0)\n",
    "    df_valid = df[mask_valid]\n",
    "    x_valid = df_valid.iloc[:, :n_feature].values\n",
    "    y_valid = df_valid.loc[:, 'label'].values\n",
    "    #logger.info(f'df_{dataset}.shape {df_valid.shape}, x_{dataset}.shape {x_valid.shape}, y_{dataset}.shape {y_valid.shape}')\n",
    "    #logger.info(f'y_{dataset} with 2 classes:')\n",
    "    count_classes(logger, df_valid.label.values)\n",
    "    return df_valid, x_valid, y_valid\n",
    "\n",
    "\n",
    "df_pos, x_pos, y_pos = \\\n",
    "    get_crop_type_x_y_pos_test(logger, df=df_te, n_feature=n_feature, dataset='from_scratch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 14:49:32,491 - INFO -   label = 0, pixel number = 6743, percentage = 100.0%\n"
     ]
    }
   ],
   "source": [
    "def get_unlabeled_pixels(logger, df, size, dataset):\n",
    "    # was in prepare.py\n",
    "    \n",
    "    mask_valid = (df.label.values == 0)\n",
    "    idx_to_sample = df[mask_valid].index\n",
    "    # Could also apply gaussian filter here\n",
    "    sampled_idx = np.random.choice(idx_to_sample, size, replace=False)\n",
    "    df_unl = df.iloc[sampled_idx, :]\n",
    "    x_unl = df_unl.iloc[:, :n_feature].values\n",
    "    y_unl = df_unl.loc[:, 'label'].values\n",
    "    count_classes(logger, df_unl.label.values)\n",
    "\n",
    "    return df_unl, x_unl, y_unl\n",
    "\n",
    "\n",
    "df_unl, x_unl, y_unl = \\\n",
    "    get_unlabeled_pixels(logger, df=df_te, size=df_pos.shape[0], dataset='from_scratch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data\n",
    "import pandas as pd\n",
    "\n",
    "df_pu = pd.concat([df_pos, df_unl], axis=0).sample(frac=1) #shuffle rows\n",
    "x_pu = np.concatenate((x_pos, x_unl), axis=0)\n",
    "y_pu = np.concatenate((y_pos, y_unl), axis=0)\n",
    "#coords_pu = gpd.GeoDataFrame(pd.concat([coords_pos, coords_unl], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 15:04:01,722 - INFO - Loading the best pretrained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leds\\Anaconda3\\envs\\sat\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\leds\\Anaconda3\\envs\\sat\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\leds\\Anaconda3\\envs\\sat\\lib\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 0.24.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "\n",
    "logger.info(\"Loading the best pretrained model...\")\n",
    "best_estimator = pickle.load(open(f'model/{pretrained[0]}.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.util import convert_partial_predictions\n",
    "from src.data.write import save_predictions_geotiff\n",
    "from sklearn.metrics import recall_score, accuracy_score\n",
    "\n",
    "def evaluate_by_recall(y_test, y_test_pred):\n",
    "    return recall_score(y_test, y_test_pred, average='macro')\n",
    "\n",
    "\n",
    "def evaluate_by_accuracy(y_test, y_test_pred):\n",
    "    return accuracy_score(y_test, y_test_pred)#, average='macro')\n",
    "    \n",
    "\n",
    "def test2(logger, model, x_test, y_test, meta, index,\n",
    "         pred_name, color_by_height, region_indicator=None):\n",
    "    \n",
    "\n",
    "    logger.info(\"## Testing\")\n",
    "    # predict\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    print(y_test_pred)\n",
    "    y_test_pred_converted = convert_partial_predictions(y_test_pred, index, meta['height'] * meta['width'])\n",
    "    # save prediction\n",
    "    pred_path = f'./preds/{pred_name}.tiff'\n",
    "    save_predictions_geotiff(y_test_pred_converted, save_path=pred_path, meta=meta,\n",
    "                             region_indicator=region_indicator, color_by_height=color_by_height)\n",
    "    logger.info(f'Saved predictions to {pred_path}')\n",
    "    # evaluate\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info('Evaluating by recall...')\n",
    "        recall = evaluate_by_recall(y_test, y_test_pred)\n",
    "        logger.info(f'\\n{recall}')\n",
    "    except:\n",
    "    \"\"\"\n",
    "    logger.info('Evaluating by accuracy...')\n",
    "    accuracy = evaluate_by_accuracy(y_test, y_test_pred)\n",
    "    logger.info(f'\\n{accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-04 15:21:55,514 - INFO - ## Testing\n",
      "[2 2 2 ... 3 2 3]\n",
      "Aligned raster!\n",
      "2022-03-04 15:22:01,688 - INFO - Saved predictions to ./preds/first_test.tiff\n",
      "2022-03-04 15:22:01,708 - INFO - Evaluating by accuracy...\n",
      "2022-03-04 15:22:01,741 - INFO - \n",
      "0.6192347619753819\n"
     ]
    }
   ],
   "source": [
    "test2(logger, best_estimator, x_pu, y_pu, meta, df_pu.index,\n",
    "    pred_name='first_test', color_by_height=True, region_indicator=label_path_dict[district])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test from cropland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_cropland_x_y(logger, df, n_feature, dataset):\n",
    "   \n",
    "    mask_valid = df.gt_cropland.values != 0\n",
    "    df_valid = df[mask_valid]  # .reset_index(drop=True)\n",
    "    x_valid = df_valid.iloc[:, :n_feature].values\n",
    "    y_valid = df_valid.loc[:, 'gt_cropland'].values\n",
    "    logger.info(\n",
    "        f'df_{dataset}.shape {df_valid.shape}, x_{dataset}.shape {x_valid.shape}, y_{dataset}.shape {y_valid.shape}')\n",
    "    logger.info(f'y_{dataset} with 3 classes:')\n",
    "    count_classes(logger, df_valid.label.values)\n",
    "    logger.info(f'y_{dataset} with 2 classes:')\n",
    "    count_classes(logger, df_valid.gt_cropland.values)\n",
    "    return df_valid, x_valid, y_valid\n",
    "    \n",
    "\n",
    "# get cropland masked data\n",
    "df_masked, x_masked, y_masked = \\\n",
    "    get_valid_cropland_x_y(logger, df_te, n_feature=n_feature, dataset='from_cropland')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get positive samples\n",
    "df_pos, x_pos, y_pos = \\\n",
    "    get_crop_type_x_y_pos(logger, df=df_masked, n_feature=n_feature, dataset='from_cropland')\n",
    "\n",
    "# get (all) unlabeled samples\n",
    "df_unl, x_unl, y_unl = \\\n",
    "    get_unlabeled_pixels(logger, df=df_masked, size=None, dataset='from_cropland')\n",
    "\n",
    "# concatenate data\n",
    "df_pu = pd.concat([df_pos, df_unl], axis=0).sample(frac=1) #shuffle rows\n",
    "x_pu = np.concatenate((x_pos, x_unl), axis=0)\n",
    "y_pu = np.concatenate((y_pos, y_unl), axis=0)\n",
    "    \n",
    "test(logger, best_estimator, x_pu, y_pu, meta, df_pu.index,\n",
    "        pred_name='first_test', color_by_height=color_by_height, region_indicator=label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old -- Get unlabeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.scv import construct_valid_grid\n",
    "\n",
    "polygons_gpd, grid = construct_valid_grid(polygons_list, tiles_x=1, tiles_y=1, shape='square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid.geometry\n",
    "grid.shape\n",
    "\n",
    "# see if to use grid.geonetry or the polgon list directly into the grid shape \n",
    "# OR the polygons total bounds\n",
    "\n",
    "# then check if it makes sense to sample from df, or instead just need to append new points to df and shuffle it\n",
    "# would then need to make sure features are crated for it \n",
    "\n",
    "# other idea: get the polygon, list, creating abounding box, select unlabeled in that box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_unlabeled_idx(coords, grid, size, meta):\n",
    "    iterable = iter([(feat, val) for feat, val in zip(grid.geometry, np.ones(grid.shape[0], dtype=int))])\n",
    "    img = rasterio.features.rasterize(iterable, out_shape=(meta['height'], meta['width']),\n",
    "                                      transform=meta['transform'])\n",
    "    mask = img.reshape(-1) == 1\n",
    "\n",
    "    valid_idx = coords.index[mask]\n",
    "\n",
    "    return np.random.choice(valid_idx, size, replace=False)  \n",
    "\n",
    "unl_idx_test = sample_unlabeled_idx(df_te.coords, grid, x_pos.shape[0], meta) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_pos = gpd.GeoDataFrame({'geometry': df_pos.coords.values})\n",
    "\n",
    "# sample unlabeled data\n",
    "unl_idx = sample_unlabeled_idx(df_te.coords, x_pos.shape[0], meta) # to update\n",
    "df_unl = df.loc[unl_idx, :]\n",
    "coords_unl = gpd.GeoDataFrame({'geometry': df_unl.loc[unl_idx, 'coords'].values})\n",
    "x_unl = df_kullu.loc[unl_idx, feature_names].values\n",
    "y_unl = np.zeros(unl_idx.shape[0], dtype=int)\n",
    "\n",
    "# concatenate\n",
    "df_pu = pd.concat([df_pos, df_unl], axis=0)\n",
    "x_pu = np.concatenate((x_pos, x_unl), axis=0)\n",
    "y_pu = np.concatenate((y_pos, y_unl), axis=0)\n",
    "coords_pu = gpd.GeoDataFrame(pd.concat([coords_pos, coords_unl], axis=0))\n",
    "\n",
    "test(logger, best_estimator, x_pu, y_pu, meta, df_pu.index,\n",
    "    pred_name='first_test', color_by_height=color_by_height, region_indicator=label_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cropland mask\n",
    "df_mask, x_mask, y_mask = \\\n",
    "get_crop_type_x_y_pos(logger, df, n_feature=n_feature, dataset='train_val_kullu')\n",
    "\n",
    "x = df.loc[:, feature_names]\n",
    "\n",
    "# predict\n",
    "pred_path = pred_path_top + 'testing.tiff' #str(row) + '_' + str(col) + '.tiff'\n",
    "\"\"\"\n",
    "predict(logger, best_estimator, x_mask, meta, color_by_height,\n",
    "        pred_path=pred_path, ancillary_dir=ancillary_dir,  \n",
    "        cropland_mask=y_mask, region_indicator=None)\n",
    "\"\"\"\n",
    "predict(logger, best_estimator, x, meta, y_mask,\n",
    "        pred_path, color_by_height, region_indicator=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geosampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import json\n",
    "from multiprocessing.dummy import Pool, Lock\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)\n",
    "\n",
    "import ee\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import urllib3\n",
    "from rasterio.transform import Affine\n",
    "from skimage.exposure import rescale_intensity\n",
    "from torchvision.datasets.utils import download_and_extract_archive\n",
    "import shapefile\n",
    "from shapely.geometry import shape, Point\n",
    "\n",
    "from datasets.seco_dataset import RGB_BANDS, ALL_BANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSampler:\n",
    "\n",
    "    def sample_point(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class GaussianSampler(GeoSampler):\n",
    "\n",
    "    def __init__(self, df, labeled_mask, std=5):\n",
    "        self.df = df\n",
    "        if labeled_mask is None:\n",
    "            self.df_labeled = None\n",
    "            self.df_unlabeled = df\n",
    "        else:\n",
    "            self.df_labeled = df[labeled_mask]\n",
    "            self.df_unlabeled = df[~labeled_mask]\n",
    "        self.std = std\n",
    "\n",
    "    def sample_point(self):\n",
    "        rng = np.random.default_rng()\n",
    "        if self.df_labeled is not None:\n",
    "            points = rng.choice(self.df_labeled, out_shape)\n",
    "        else:\n",
    "            points = rng.choice(self.df, out_shape)\n",
    "        std = self.km2deg(self.std)\n",
    "        lon, lat = np.random.normal(loc=points, scale=[std, std])\n",
    "        return [lon, lat]\n",
    "\n",
    "    @staticmethod\n",
    "    def km2deg(kms, radius=6371):\n",
    "        return kms / (2.0 * radius * np.pi / 360.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "points = [[1,0,1], [0,0,1]]\n",
    "std=0.5\n",
    "print(\"test\")\n",
    "print(np.random.normal(loc=points, scale=[std, std]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2fd1516b826c65d9f1745c57e793959ac8e846bd891ab340d6e4f05a9475e44b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sat')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
